\chapter{Fundamentals}
\label{chapter:fundamentals}

A real-time system \cite{liu2000real} is one where the correctness of the system behavior is dependent not only on the logical results of the computation but also on the physical time when these results are produced. Here, the system \emph{behavior} refers to the sequence of outputs over time of the system. The flow of time is modeled as a directed line that extends from the past into the future. A slice of time in this line is called an \emph{instant}. Any ideal occurrence at a time instant is called an \emph{event}. An interval on this time line is called the \emph{duration}, defined by two events, the start event and the end or terminating event. This timeline is digital when the time line is partitioned into a sequence of equally spaced durations, called clock \emph{ticks}. A real-time system typically changes as a function of physical time. If the real-time system is \emph{distributed}, then it consists of a set of computers, \emph{nodes}, interconnected by a real-time communication network.

% Describe Real-time Systems
Real-time systems are subject to strict operational deadlines. These deadlines constrain the amount of time permitted to elapse between a stimulus provided to the system and a response generated by the system. Consequently, the correctness of such systems depends heavily on its temporal and functional behavior. Real-time programs that are logically correct i.e. implement the intended functions, may not operate correctly if the required timing properties are not met. Typically, such systems are classified as either soft or hard real-time systems. In soft real-time systems, missing deadlines does not completely degrade the overall system performance e.g. delays in opening a web browser does not render the web browser useless; the browser, as an entity is still functional. Hard real-time systems, however, are systems where missed deadlines could be critical e.g. delays in pacemaker timing cycles leads to irregular heart beats with potentially fatal consequences. It is important that any error within the system e.g. data loss or corruption, node failure etc. be detected within a short time with a very high probability. The required error-detection latency must often be in the same order of magnitude as the sampling period of the fastest critical control loop. Then, it is possible to perform corrective action, or bring the system to a safe state. This makes the design of hard real-time systems different from soft real-time systems. The demanding response time requirements, often in milliseconds or less, preclude human intervention during normal operation. A hard real-time system must be highly autonomous to maintain safe operation. In contrast, the response time requirements of soft real-time systems is often in the order of seconds. 

% Components in a real-time system model
A Cyber-Physical System (CPS) can be decomposed into three communicating entities; (1) a controlled object; could be a physical subsystem, (2) a (potentially distributed) computer system executing programs, and (3) a human user. The computer system consists of computational nodes that interact by exchanging messages. Each node can host one or more computational \emph{components}. In this model, a component is a self-contained hardware/software unit that interacts with its environment by exchanging messages. A timed sequence of output messages that a component produces represents its \emph{behavior}. An unintended behavior is called a \emph{failure}. A real-time component contains a real-time clock and is thus aware of the progression of time. When triggered, a component starts executing its predefined computations at the start instant.  The communication infrastructure provides for the transport of unidirectional \emph{messages} from a sender component to one or more receiver components within a given interval of time. Unidirectional messages create a causal chain and eliminate dependencies between senders and receivers. A message is sent at a \emph{send instant} and received at the receiver at some later \emph{receive instant}. The temporal properties of a message include information about the temporal order, the send instant and latency of transport. A message contains a data field that holds a data structure that is transported between components. The communication interface is agnostic about the contents of this data field. 

The \emph{state} of a real-time component represents a separation between past and future component behaviors i.e. there must be a consistent temporal order among the events of significance to a component. Component states enable the determination of a future output solely on the basis of the future input and the present state of the system i.e. state embodies all of system history. Here, a component is a self-contained validated unit that can be used as a building block in the construction of larger systems. In order to enable a composition of a component into a distributed set of components, the principle of \emph{composability} should be observed. A set of components are said to be composable with respect to a specified property if the system integration will not invalidate this property, once the property has been established on the subsystem level. Examples of such properties include timeliness or testability. In composable systems, the system properties follow from the properties of the individual components. This means that in a composed architecture, the introduced abstraction of a component must remain intact, even if the component becomes faulty i.e. it must be possible to replace a faulty component without any knowledge about the component internals. Note that this principle constrains the implementation of a component, because it restricts the implicit sharing of resources among components; if a shared resource fails, more than one component is affected by the failure. 

Timing and schedulability analysis in real-time systems usually assumes an ideally functioning software program where every step of computation performs as expected and characterizes these steps with timing properties such as worst-case execution times (WCET) \cite{wilhelm2008worst} or response times \cite{joseph1986finding}. Once a \emph{timing model} of the system is realized, the behavior can be analyzed by using either a discrete event simulator, prototypical testing or formal analysis methods. This thesis concentrates on a formal analysis approach to analyzing the temporal behavior of a class of distributed real-time embedded systems.

\emph{Verification} establishes a consistency between the formal system specification and the system requirements, while \emph{validation} is concerned with the consistency between the model of the user's intentions and the system requirements. The missing link between verification and validation is the relationship between the user's intentions i.e. informal specification and the formal system specification. Discrepancies between these notations are called \emph{system specification errors}. Verification is usually reduced to a mathematical analysis process, while validation must examine the system's behavior in the real-world. If properties of a system have been formally verified, it still has not been established whether the existing formal specification captures all the aspects of the intended behavior in the user's real-world environment. To be free of specification errors, validation and specification testing are required for quality assurance. The primary verification method is \emph{formal analysis} and the primary validation method is \emph{testing}. The following chapter reviews various general analysis methodologies, including software testing and formal verifications methods, and also selective system-level analysis methodologies for concurrent real-time systems that are related to this dissertation. 

\if 0

There are several challenges to modeling and analysis of such distributed safety-critical systems. Using real-time components that can run on heterogeneous hardware platforms means that the components have different timing characteristics on the different platforms. Therefore, a component must be molded and re-verified for each hardware platform on which it is deployed. Secondly, component-based systems are constructed by assembling a tested set of components. Two components that individually provide timing guarantees may not aid the overall system-level requirements when executed concurrently in a specific hardware platform. The challenge here is ensuring that a system consisting of composed set of verified components still retains its timing behavior. Thus, the requirements for timing analysis become two fold: 

\begin{itemize}
	\item Verify the timing properties of each component in the system - Does the operational behavior of a software component meet its timing requirements?
	
	\item Analyze the schedulability of a component assembly - When composed together, do all components work as expected to meet the end-to-end system-wide timing requirements?
\end{itemize}

The results of this two-level timing analysis should indicate with sufficient proof the stability or instability of the composed component-based system. Achieving this workflow is the fundamental goal of our timing analysis methodology, presented in later sections. Our analysis model uses a Colored Petri Net \cite{CPN} based formal analysis methodology. However, motivating this methodology requires first an in-depth literature review. The following section reviews both general analysis methodologies used in the past, and specific system-level modeling and timing analysis techniques for concurrent real-time systems, along with advantages, limitations and potential improvements that motivate our presented work.

\fi